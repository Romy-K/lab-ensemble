{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6606, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop nulls\n",
    "spaceship = spaceship.dropna().reset_index(drop=True)  # Drop nulls\n",
    "spaceship.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin\n",
      "F    2152\n",
      "G    1973\n",
      "E     683\n",
      "B     628\n",
      "C     587\n",
      "D     374\n",
      "A     207\n",
      "T       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Keep only the first letter of Cabin\n",
    "\n",
    "spaceship['Cabin'] = spaceship['Cabin'].str[0]\n",
    "\n",
    "print(spaceship.Cabin.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop PassengerId and Name\n",
    "spaceship = spaceship.drop(['PassengerId', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  Transported  \\\n",
      "0     39.0          0.0        0.0           0.0     0.0     0.0        False   \n",
      "1     24.0        109.0        9.0          25.0   549.0    44.0         True   \n",
      "2     58.0         43.0     3576.0           0.0  6715.0    49.0        False   \n",
      "3     33.0          0.0     1283.0         371.0  3329.0   193.0        False   \n",
      "4     16.0        303.0       70.0         151.0   565.0     2.0         True   \n",
      "...    ...          ...        ...           ...     ...     ...          ...   \n",
      "6601  41.0          0.0     6819.0           0.0  1643.0    74.0        False   \n",
      "6602  18.0          0.0        0.0           0.0     0.0     0.0        False   \n",
      "6603  26.0          0.0        0.0        1872.0     1.0     0.0         True   \n",
      "6604  32.0          0.0     1049.0           0.0   353.0  3235.0        False   \n",
      "6605  44.0        126.0     4688.0           0.0     0.0    12.0         True   \n",
      "\n",
      "      HomePlanet_Earth  HomePlanet_Europa  HomePlanet_Mars  ...  Cabin_D  \\\n",
      "0                    0                  1                0  ...        0   \n",
      "1                    1                  0                0  ...        0   \n",
      "2                    0                  1                0  ...        0   \n",
      "3                    0                  1                0  ...        0   \n",
      "4                    1                  0                0  ...        0   \n",
      "...                ...                ...              ...  ...      ...   \n",
      "6601                 0                  1                0  ...        0   \n",
      "6602                 1                  0                0  ...        0   \n",
      "6603                 1                  0                0  ...        0   \n",
      "6604                 0                  1                0  ...        0   \n",
      "6605                 0                  1                0  ...        0   \n",
      "\n",
      "      Cabin_E  Cabin_F  Cabin_G  Cabin_T  Destination_55 Cancri e  \\\n",
      "0           0        0        0        0                        0   \n",
      "1           0        1        0        0                        0   \n",
      "2           0        0        0        0                        0   \n",
      "3           0        0        0        0                        0   \n",
      "4           0        1        0        0                        0   \n",
      "...       ...      ...      ...      ...                      ...   \n",
      "6601        0        0        0        0                        1   \n",
      "6602        0        0        1        0                        0   \n",
      "6603        0        0        1        0                        0   \n",
      "6604        1        0        0        0                        1   \n",
      "6605        1        0        0        0                        0   \n",
      "\n",
      "      Destination_PSO J318.5-22  Destination_TRAPPIST-1e  VIP_False  VIP_True  \n",
      "0                             0                        1          1         0  \n",
      "1                             0                        1          1         0  \n",
      "2                             0                        1          0         1  \n",
      "3                             0                        1          1         0  \n",
      "4                             0                        1          1         0  \n",
      "...                         ...                      ...        ...       ...  \n",
      "6601                          0                        0          0         1  \n",
      "6602                          1                        0          1         0  \n",
      "6603                          0                        1          1         0  \n",
      "6604                          0                        0          1         0  \n",
      "6605                          0                        1          1         0  \n",
      "\n",
      "[6606 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use dummies on non-numerical columns \n",
    "# Get non-numerical columns \n",
    "non_num_columns = spaceship.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Use get_dummies to transform these columns\n",
    "spaceship_with_dummies = pd.get_dummies(spaceship, columns=non_num_columns, dtype=int) #(I got booleans before specifying int)\n",
    "\n",
    "print(spaceship_with_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = spaceship_with_dummies.drop('Transported', axis=1)\n",
    "target = spaceship_with_dummies['Transported']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)   # fit scaler on training data, transform training data\n",
    "X_test_scaled = scaler.transform(X_test)         # only transform test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model \n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=100,\n",
    "                               max_samples = 0.8,\n",
    "                               max_features = 1.0,\n",
    "                               random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging accuracy: 0.7881996974281392\n"
     ]
    }
   ],
   "source": [
    "# Fit the bag \n",
    "\n",
    "bagging.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "\n",
    "y_pred = bagging.predict(X_test_scaled)\n",
    "accuracy = bagging.score(X_test_scaled, y_test)\n",
    "print(\"Bagging accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7881996974281392\n",
      "Precision: 0.7908396946564885\n",
      "Recall: 0.783661119515885\n",
      "F1 Score: 0.7872340425531915\n"
     ]
    }
   ],
   "source": [
    "# More evaluation \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7912254160363086\n",
      "Precision: 0.7975270479134466\n",
      "Recall: 0.7806354009077155\n",
      "F1 Score: 0.7889908256880734\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the model \n",
    "forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = forest.predict(X_test_scaled)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.7859304084720121\n",
      "Precision: 0.761049723756906\n",
      "Recall: 0.8335854765506808\n",
      "F1 Score: 0.7956678700361011\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "gb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = gb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.7844175491679274\n",
      "Precision: 0.7685714285714286\n",
      "Recall: 0.8139183055975794\n",
      "F1 Score: 0.7905951506245408\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the model\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = ada.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If accuracy is the most important metric, Random Forest is the best. If we give more weight to Recall, Gradient Boosting is the best. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
